1. Read the PDF (Airbus manual): (Complexity: Low)
    - Script with Python or other programming language
    - Read with AI tool (Dataworkz, landing.ai, doclink)

2. Transform the PDF into embeddings ((Complexity: Low)
    - Script with Python or other programming language
    - Read with AI tool (Dataworkz, landing.ai, doclink)

3. Agent shows the checklist and reads outloud (Complexity: Very High)
    - Read the operations from the database. * checklist collection
    - Provide the text to the API to transform it into speech
    - Agent reads the text outloud

4. User confirms if the item is completed, check, done. User provides an answer to the agent. (Complexity: Very High)
    - User provides a speech that it converted into text
    - Speech is sent to the API to transform it into text
    - The text is used to recognize the action, by the agent, example: "Yes", "Check", "Done", "Complete".
    - Agent returns a check confirmation

4(a). User can ask a question to the agent (What's an APU) (Complexity: Medium)
    - Convert the speech to text (Transform the user's question (speech) into text)
    - Transform the text (user's question) into embeddings * 
    - Perform a vector search query against:
        a) Against the MongoDB database with the manual's embeddings
        b) Send the text (question) to the AI tool (Dataworkz, landing.ai, doclink) ** Change the retrieval from vertexAI
    - Get the answer to the question (text), transform it into speech 
    - The agent reads the answer outloud 

5. Complete operations, saves the data into the database (Complexity: Low)
    - Once the checklist completed, save the data into MongoDB *archive collection




